{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data with Conversation Starters\n",
    "\n",
    "Contoso Zoo is developing an AI-powered smart guide app to enhance visitors' experiences. The app aims to answer questions about wildlife. To evaluate the responses from the app, we need to create a comprehensive synthetic question-answer dataset that covers various aspects of wildlife, including animal behavior, habitat preferences, and dietary needs. <br>\n",
    "\n",
    "In this exercise, you will generate a synthetic question-answer dataset for the Contoso Zoo app. This dataset will not only include standard question-answer pairs but also incorporate conversation starters to simulate contextually relevant interactions. These conversation starters will allow for pre-specified, repeatable user turns in a conversation, which is crucial for evaluating the AI's performance across different scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages\n",
    "\n",
    "To begin, we'll install the packages that are necessary for completing the simulation. The `Simulator` class is within the `simulator` package of the Azure AI Evaluation SDK. With security in mind, we'll authenticate with Azure services using `azure-identity`. And finally, since we'll be interacting with OpenAI's services via Azure, the `openai` package will come in handy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-evaluation azure-identity openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "We'll now import the `Simulator` class alongside several additional packages and modules that'll be necessary for running the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.ai.evaluation.simulator import Simulator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from typing import List, Dict, Any, Optional\n",
    "from openai import AzureOpenAI\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables to create an instance of the simulator\n",
    "\n",
    "We'll now set the environment variables that'll be required to create an instance of the `Simulator` class. You'll need the following:\n",
    "\n",
    "- Azure OpenAI endpoint\n",
    "- Azure OpenAI API Key\n",
    "- Azure deployment\n",
    "- Azure API version\n",
    "\n",
    "You can locate your **Azure endpoint** and **Azure API Key** by navigating to **Connections** and copying the respective credentials for your Azure OpenAI resource.\n",
    "\n",
    "The name of your Azure deployment is provided on the **Deployment** page.\n",
    "\n",
    "The **Azure API version** is available within the [Latest GA API Release](https://learn.microsoft.com/azure/ai-services/openai/api-version-deprecation#latest-ga-api-release) article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AZURE_OPENAI_ENDPOINT'] = 'Your OpenAI endpoint'\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = 'Your OpenAI API key'\n",
    "os.environ['AZURE_OPENAI_DEPLOYMENT'] = 'Your deployment'\n",
    "os.environ['OPENAI_API_VERSION'] = 'The OpenAI API version'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the model_config\n",
    "\n",
    "The `model_config` is necessary as it's a required parameter when creating an instance of the `Simulator` class. Let's configure the `model_config` with the following:\n",
    "\n",
    "- Azure OpenAI endpoint\n",
    "- Azure OpenAI API key\n",
    "- Azure deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "}\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of the Simulator class\n",
    "\n",
    "We now need to create an instance of the `Simulator` class which will later be used to run the simulator. We'll need to initialize the `simulator` object with both the Azure AI Project and the credential. Fortunately, we store our Azure AI Project configuration within the `azure_ai_project` variable. Also, here is where we'll use the `DefaultAzureCredential` class to retrieve the default credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a call to your application\n",
    "\n",
    "We'll now create a function that'll create a call to your application which should take a user query and return a response. \n",
    "\n",
    "The call to the AI model includes parameters which specifies the model, messages, and additional settings which impact the model's response. \n",
    "\n",
    "We'll later send a query to the AI model and retrieve the repsonse. Once the repsonse is retrieved, we'll convert the completion object to a dictionary and extract the message before returning the message content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_to_your_ai_application(query: str) -> str:\n",
    "    # logic to call your application\n",
    "    # use a try except block to catch any errors\n",
    "    deployment = os.environ.get(\"AZURE_DEPLOYMENT\")\n",
    "    endpoint = os.environ.get(\"AZURE_ENDPOINT\")\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=os.environ.get(\"AZURE_API_VERSION\"),\n",
    "        api_key=os.environ.get(\"AZURE_API_KEY\"),\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "    )\n",
    "    message = completion.to_dict()[\"choices\"][0][\"message\"]\n",
    "    # change this to return the response from your application\n",
    "    return message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a callback\n",
    "\n",
    "We'll now create a `callback` which will handle incoming messages, process them using the app, and format the response to follow the OpenAI chat protocol format. \n",
    "\n",
    "The `callback` function will extract the latest message from the conversation history, reset the context, and then call the app to get a response based on the latest message. \n",
    "\n",
    "Afterwards, the response will be formatted to follow the OpenAI chat protocol format, and then appended to the conversation history. We'll retun the updated conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def callback(\n",
    "    messages: List[Dict],\n",
    "    stream: bool = False,\n",
    "    session_state: Any = None,  # noqa: ANN401\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict:\n",
    "    messages_list = messages[\"messages\"]\n",
    "    # get last message\n",
    "    latest_message = messages_list[-1]\n",
    "    query = latest_message[\"content\"]\n",
    "    context = None\n",
    "    # call your endpoint or ai application here\n",
    "    response = call_to_your_ai_application(query)\n",
    "    # we are formatting the response to follow the openAI chat protocol format\n",
    "    formatted_response = {\n",
    "        \"content\": response,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": {\n",
    "            \"citations\": None,\n",
    "        },\n",
    "    }\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state, \"context\": context}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create conversation starters\n",
    "\n",
    "When defining the conversation starters, we want to provide examples that are relevant to a real-world use-case. Here we provide 2 conversation starters for two separate conversations.\n",
    "\n",
    "The first conversation simulates a person discussing lions with the app. The second conversation simulates a parent inquiring about birds with the app. Both conversations are stored within a `conversations_turns` list.\n",
    "\n",
    "**Note**: Later when you run the simulator, if you consistently exceed quota, remove one of the simulations from the `conversation_turns` list and run the subsequent cells once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_turns = [\n",
    "    # simulation 1\n",
    "    [\n",
    "        \"I'm standing in front of the lion enclosure, and I've never seen a real lion before!\",  # simulator conversation starter (turn 1)\n",
    "        \"Wow, the lion is much bigger than I expected! How much do they typically weigh?\",  # conversation turn 2,\n",
    "        \"I notice the lion is just lying there. Do they sleep a lot? What do they do most of the day?\",  # conversation turn 3\n",
    "    ],\n",
    "    # simulation 2\n",
    "    [\n",
    "        \"My child is fascinated by the colorful birds in the aviary. She keeps asking about their feathers.\",\n",
    "        \"My daughter wants to know why some birds have such bright colors while others are more dull. Can you explain?\",\n",
    "        \"She's now wondering if birds can change the color of their feathers like chameleons change their skin color.\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a call to the simulator\n",
    "\n",
    "Let's now create a call to run the simulation and process the conversation turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputs = await simulator(\n",
    "    target=callback,\n",
    "    conversation_turns=conversation_turns,\n",
    "    max_conversation_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the generated data\n",
    "\n",
    "Finally, save the generated data to a `.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = Path(\"conversation_starter_output.json\")\n",
    "with output_file.open(\"a\") as f:\n",
    "    json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete resources\n",
    "\n",
    "If you've finished exploring Azure AI Services, delete the Azure resource that you created during the workshop.\n",
    "\n",
    "**Note**: You may be prompted to delete your deployed model(s) before deleting the resource group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
